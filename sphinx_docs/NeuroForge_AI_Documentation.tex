% PREÁMBULO EXACTO - COPIAR LITERALMENTE:
\documentclass[12pt,a4paper]{report}

% Fuentes CRÍTICAS para compatibilidad Word
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{helvet} % Helvetica para texto principal
\usepackage{courier} % Courier para código
\renewcommand{\familydefault}{\sfdefault} % Helvetica como default

% Paquetes esenciales
\usepackage{tocbibind}
\setcounter{tocdepth}{3}
\setcounter{secnumdepth}{3}
\usepackage{microtype}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{appendix}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{enumitem}
\usepackage{titlesec}

% Configuración de márgenes
\geometry{
    left=2.5cm,
    right=2.5cm,
    top=2.5cm,
    bottom=2.5cm,
    headheight=15pt
}

% Configuración listings EXACTA para código
\lstset{
    basicstyle=\ttfamily\footnotesize\fontfamily{pcr}\selectfont,
    backgroundcolor=\color{gray!10},
    frame=single,
    frameround=tttt,
    rulecolor=\color{gray!50},
    numbers=left,
    numberstyle=\tiny\color{gray},
    keywordstyle=\color{blue}\bfseries,
    commentstyle=\color{green!60!black}\itshape,
    stringstyle=\color{red},
    showstringspaces=false,
    breaklines=true,
    breakatwhitespace=true,
    tabsize=2,
    captionpos=b,
    xleftmargin=2em,
    framexleftmargin=1.5em,
    belowskip=1em,
    aboveskip=1em
}

% Headers y footers con sans-serif
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\color{blue!70!black}\textbf{\sffamily\leftmark}}
\fancyhead[R]{\color{blue!70!black}\textbf{\sffamily\thepage}}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}
\fancyfoot[C]{\color{gray}\small\sffamily NeuroForge AI - Advanced Training Orchestration Platform}

% Estilos de capítulos y secciones con sans-serif
\titleformat{\chapter}[display]
{\normalfont\huge\bfseries\sffamily\color{blue!70!black}}
{\chaptertitlename\ \thechapter}{20pt}{\Huge}
\titlespacing*{\chapter}{0pt}{-30pt}{20pt}

\titleformat{\section}
{\normalfont\Large\bfseries\sffamily\color{blue!70!black}}
{\thesection}{1em}{}
\titlespacing*{\section}{0pt}{15pt}{10pt}

\titleformat{\subsection}
{\normalfont\large\bfseries\sffamily\color{orange!80!black}}
{\thesubsection}{1em}{}
\titlespacing*{\subsection}{0pt}{10pt}{5pt}

% Configuración hyperref
\hypersetup{
    colorlinks=true,
    linkcolor=blue!70!black,
    filecolor=blue!70!black,
    urlcolor=blue!70!black,
    citecolor=orange!80!black,
    pdftitle={NeuroForge AI - Advanced Training Orchestration Platform},
    pdfauthor={William Rodriguez},
    pdfsubject={MLOps, AI Training, React, TypeScript},
    pdfkeywords={NeuroForge, MLOps, AI Training, React, TypeScript, Docker}
}

\begin{document}

% Página de título SIMPLE
\begin{titlepage}
    \centering
    \vspace*{2cm}
    \includegraphics[width=0.25\textwidth]{sources/kubernetes-logo.png}
    \vspace{1cm}
    {\color{blue!70!black}\Huge\textbf{NeuroForge AI}}\\[0.5cm]
    {\color{orange!80!black}\Large\textbf{Advanced Training Orchestration Platform}}\\[1cm]
    {\large\textit{A Modern Implementation Guide for}}\\[0.3cm]
    {\Large\textbf{YOLO Model Training with Genetic Algorithms}}\\[1.5cm]
    {\large\textbf{\today}}
    \vfill
    \colorbox{blue!70!black}{
        \color{white}\textbf{React + TypeScript + Docker + MLOps}
    }
\end{titlepage}

% Página de autor SEPARADA
\begin{titlepage}
    \centering
    \vspace*{3cm}
    {\color{blue!70!black}\Large\textbf{Author}}\\[1cm]
    {\Large\textbf{William Rodriguez}}\\[0.5cm]
    \textit{Software Engineer \& System Architect}\\[0.3cm]
    \textit{eCaptureDtech}\\[0.2cm]
    \textit{Badajoz, Extremadura, España}\\[1cm]
    \begin{tabular}{c}
        \textbf{Contact Information:}\\[0.5cm]
        LinkedIn: es.linkedin.com/in/wisrovi-rodriguez\\[0.2cm]
        Email: william.rodriguez@ecapturedtech.com\\[0.2cm]
        GitHub: github.com/wisrovi
    \end{tabular}
    \vfill
    \colorbox{orange!80!black}{
        \color{white}\textbf{Expert in MLOps and AI Infrastructure}
    }
\end{titlepage}

% Tabla de contenidos
\tableofcontents
\cleardoublepage

% Listas
\listoffigures
\cleardoublepage
\listoftables
\cleardoublepage
\lstlistoflistings
\cleardoublepage

\chapter{Executive Summary}

NeuroForge AI represents a paradigm shift in machine learning training orchestration, providing a sophisticated web-based platform designed to manage complex YOLO (You Only Look Once) model training workflows across distributed GPU clusters. Built with modern React 19 and TypeScript, the platform serves as a centralized command center that bridges the gap between raw computational power and intelligent model evolution through genetic algorithms and hyperparameter optimization.

The architecture leverages a microservices-based approach with seamless integration to industry-standard tools including MLflow for experiment tracking, MinIO for high-performance object storage, Redis for job queuing, and Ray Tune for scalable hyperparameter optimization. The platform's intuitive interface provides real-time monitoring of cluster performance, GPU utilization, and training progress while maintaining robust role-based access control and team collaboration features.

Key innovations include automated hyperparameter evolution using genetic algorithms, intelligent resource allocation across distributed GPU nodes, and comprehensive experiment lifecycle management. The system supports both development and production deployments through Docker containerization, offering scalable infrastructure that can grow from single-node setups to enterprise-grade GPU clusters. With its API-first design and comprehensive REST interface, NeuroForge AI enables seamless integration into existing MLOps pipelines and CI/CD workflows.

\chapter{Introduction}

\section{Background}

The rapid evolution of machine learning operations (MLOps) has created a critical need for sophisticated orchestration platforms that can manage the complexity of modern AI workflows. Organizations deploying machine learning models at scale face numerous challenges including resource management, experiment tracking, team collaboration, and infrastructure monitoring. Traditional approaches often involve disparate tools and manual processes, leading to inefficiencies, reduced reproducibility, and increased operational overhead.

NeuroForge AI emerges as a response to these challenges, providing a unified platform that integrates essential MLOps components into a cohesive, user-friendly interface. The platform draws inspiration from industry best practices and addresses common pain points encountered in production ML environments, such as the need for real-time monitoring, streamlined experiment management, and efficient resource utilization.

\section{Objectives}

The primary objectives of NeuroForge AI include:

\begin{itemize}
    \item \textbf{Centralized Management}: Provide a single interface for managing all aspects of ML workflows, from data ingestion to model deployment
    \item \textbf{Real-time Monitoring}: Offer comprehensive dashboard capabilities for tracking system performance, GPU utilization, and training progress
    \item \textbf{Role-based Access}: Implement granular access control to ensure appropriate permissions for different user types
    \item \textbf{Scalable Architecture}: Design a modular system that can grow with organizational needs and handle increasing workloads
    \item \textbf{Developer Experience}: Create an intuitive interface that reduces the learning curve for ML engineers and data scientists
\end{itemize}

\section{Scope}

This documentation covers the complete implementation of NeuroForge AI, including its architecture, deployment procedures, configuration requirements, and usage patterns. The platform is designed to work with containerized environments and integrates with popular MLOps tools such as MLflow for experiment tracking, Redis for job queuing, and MinIO for object storage. While the core functionality is self-contained, the architecture allows for extensibility and integration with existing enterprise systems.

\chapter{Technical Architecture}

\section{System Overview}

NeuroForge AI follows a modern web application architecture with clear separation of concerns between frontend presentation, business logic, and external service integrations. The application is built using React with TypeScript, providing type safety and enhanced developer experience. The architecture emphasizes component reusability, state management efficiency, and responsive design principles.

\begin{figure}[H]
    \centering
    \texttt{
    \begin{tabular}{|c|}
    \hline
    \textbf{Frontend Layer (React + TypeScript)} \\
    \hline
    \textbf{State Management (React Hooks)} \\
    \hline
    \textbf{Service Integration Layer} \\
    \hline
    \textbf{External Services (MLflow, Redis, MinIO)} \\
    \hline
    \textbf{Container Runtime (Docker)} \\
    \hline
    \end{tabular}
    }
    \caption{High-level system architecture layers}
\end{figure}

\section{Component Architecture}

The application is structured around a modular component architecture where each major feature is encapsulated in its own React component. This approach promotes maintainability and allows for independent development and testing of individual features.

\begin{lstlisting}[language=TypeScript, caption=Core Application Structure]
// Main application component with state management
const App: React.FC = () => {
  // Application modes
  const [showSplash, setShowSplash] = useState(true);
  const [showPresentation, setShowPresentation] = useState(false);
  
  // Theme and user management
  const [isDarkMode, setIsDarkMode] = useState<boolean>(true);
  const [userRole, setUserRole] = useState<UserRole>('guest');
  
  // Service and data management
  const [services, setServices] = useState<Microservice[]>([]);
  const [users, setUsers] = useState<UserProfile[]>([]);
  const [projects, setProjects] = useState<ProjectDefinition[]>([]);
  
  // Component rendering logic
  return (
    <>
      {showSplash && <SplashScreen />}
      <Sidebar />
      <Header />
      <main>
        {/* Dynamic content based on active service */}
      </main>
    </>
  );
};
\end{lstlisting}

\section{State Management Strategy}

NeuroForge AI employs React's built-in state management using hooks, combined with localStorage for persistence. This approach provides a lightweight yet effective solution for managing application state across user sessions.

\begin{lstlisting}[language=TypeScript, caption=State Persistence Pattern]
// Persistent state management with localStorage
const [services, setServices] = useState<Microservice[]>(() => {
  const saved = localStorage.getItem('omni_services_config');
  return saved ? JSON.parse(saved) : DEFAULT_MICROSERVICES;
});

// Automatic persistence on state changes
useEffect(() => {
  localStorage.setItem('omni_services_config', JSON.stringify(services));
}, [services]);
\end{lstlisting}

\section{Service Integration Architecture}

The platform integrates with external services through a well-defined configuration system that allows for dynamic service registration and management. Each service is defined as a Microservice object with metadata including URLs, icons, access permissions, and descriptions.

\begin{lstlisting}[language=TypeScript, caption=Service Configuration Interface]
interface Microservice {
  id: string;
  name: string;
  description: string;
  url: string;
  icon: ReactNode;
  minRole?: UserRole;
}
\end{lstlisting}

\chapter{Installation Guide}

\section{Prerequisites}

Before installing NeuroForge AI, ensure your system meets the following requirements:

\begin{itemize}
    \item \textbf{Node.js}: Version 18.0 or higher
    \item \textbf{Docker}: Latest stable version with Docker Compose
    \item \textbf{Git}: For version control operations
    \item \textbf{Memory}: Minimum 4GB RAM (8GB recommended)
    \item \textbf{Storage}: Minimum 10GB available disk space
\end{itemize}

\section{Local Development Setup}

\subsection{Clone and Install Dependencies}

\begin{lstlisting}[language=bash, caption=Repository Setup]
# Clone the repository
git clone <repository-url>
cd NeuralForgeAI

# Install Node.js dependencies
npm install

# Create environment configuration
cp .env.example .env
# Edit .env with your configuration
\end{lstlisting}

\subsection{Environment Configuration}

Create a \texttt{.env} file in the project root with the following configuration:

\begin{lstlisting}[language=bash, caption=Environment Variables]
# Gemini AI API Configuration
GEMINI_API_KEY=your_gemini_api_key_here

# Application Configuration
NODE_ENV=development
PORT=3000

# External Service URLs
MLFLOW_URL=http://localhost:5000
REDIS_URL=http://localhost:6379
MINIO_URL=http://localhost:9000
\end{lstlisting}

\subsection{Running the Development Server}

\begin{lstlisting}[language=bash, caption=Development Server Startup]
# Start the development server
npm run dev

# The application will be available at:
# http://localhost:3000
\end{lstlisting}

\section{Production Deployment}

\subsection{Docker Deployment}

The recommended production deployment method uses Docker containers:

\begin{lstlisting}[language=bash, caption=Docker Deployment Commands]
# Build and start the container
docker-compose up --build -d

# View container logs
docker-compose logs -f

# Stop the application
docker-compose down
\end{lstlisting}

\subsection{Dockerfile Analysis}

The Dockerfile follows a multi-stage build pattern for optimization:

\begin{lstlisting}[language=bash, caption=Dockerfile Structure]
# Build stage
FROM node:18-alpine AS builder
WORKDIR /app
COPY package*.json ./
RUN npm install
COPY . .
RUN npm run build

# Production stage
FROM node:18-alpine
WORKDIR /app
COPY --from=builder /app/dist ./dist
COPY --from=builder /app/node_modules ./node_modules
COPY --from=builder /app/package.json ./package.json
EXPOSE 4173
CMD ["npm", "run", "preview", "--", "--host", "0.0.0.0"]
\end{lstlisting}

\chapter{Configuration and Customization}

\section{Service Configuration}

NeuroForge AI uses a flexible service configuration system that allows administrators to customize available services based on organizational needs. Services are defined in the constants file and can be extended or modified.

\begin{lstlisting}[language=TypeScript, caption=Service Definition Example]
export const DEFAULT_MICROSERVICES: Microservice[] = [
  {
    id: 'dashboard',
    name: 'Dashboard',
    description: 'Cluster overview and telemetry',
    url: 'internal:dashboard',
    icon: <LayoutDashboard size={20} />,
  },
  {
    id: 'mlflow',
    name: 'MLflow Tracking',
    description: 'Experiment logging and metrics',
    url: 'http://mlflow.example.com',
    icon: <GitBranch size={20} />,
    minRole: 'admin'
  }
];
\end{lstlisting}

\section{User Role Management}

The platform implements role-based access control with two primary roles:

\begin{table}[H]
    \centering
    \begin{tabular}{@{}lll@{}}
        \toprule
        \textbf{Role} & \textbf{Permissions} & \textbf{Access Level} \\
        \midrule
        Admin & Full system access & All services \\
        Guest & Limited access & Non-admin services only \\
        \bottomrule
    \end{tabular}
    \caption{User role permissions matrix}
\end{table}

\section{Theme Customization}

The application supports both light and dark themes with automatic persistence:

\begin{lstlisting}[language=TypeScript, caption=Theme Management Implementation]
const handleThemeToggle = () => {
  setIsDarkMode(!isDarkMode);
  const root = window.document.documentElement;
  if (isDarkMode) {
    root.classList.add('dark');
  } else {
    root.classList.remove('dark');
  }
};
\end{lstlisting}

\chapter{Usage Examples}

\section{Dashboard Navigation}

The main dashboard provides an overview of system status and quick access to all services. Users can navigate between services using the sidebar navigation or the command palette (Ctrl/Cmd + K).

\begin{lstlisting}[language=TypeScript, caption=Command Palette Implementation]
const CommandPalette: React.FC = () => {
  const handleKeyDown = (e: KeyboardEvent) => {
    if ((e.metaKey || e.ctrlKey) && e.key === 'k') {
      e.preventDefault();
      setShowCommandPalette(true);
    }
  };
  
  return (
    <div className="command-palette">
      {/* Search and service selection interface */}
    </div>
  );
};
\end{lstlisting}

\section{Project Management}

The project registry allows administrators to manage ML experiments and track their lifecycle:

\begin{lstlisting}[language=TypeScript, caption=Project Management Interface]
interface ProjectDefinition {
  id: string;
  name: string;
  description: string;
  createdAt: string;
}

const handleAddProject = (project: ProjectDefinition) => {
  setProjects(prev => [...prev, project]);
};
\end{lstlisting}

\section{Training Launch}

The training launch interface provides a streamlined way to start new ML experiments:

\begin{lstlisting}[language=TypeScript, caption=Training Launch Configuration]
const LaunchTrainingView: React.FC = () => {
  const [selectedProject, setSelectedProject] = useState<string>('');
  const [selectedUser, setSelectedUser] = useState<string>('');
  
  const handleLaunchTraining = () => {
    // Training launch logic
    console.log(`Launching training for project: ${selectedProject}`);
  };
  
  return (
    <div className="training-launch">
      {/* Training configuration form */}
    </div>
  );
};
\end{lstlisting}

\chapter{Performance Metrics}

\section{System Monitoring}

The dashboard provides real-time monitoring of key system metrics:

\begin{table}[H]
    \centering
    \begin{tabular}{@{}ll@{}}
        \toprule
        \textbf{Metric} & \textbf{Description} \\
        \midrule
        Active Workers & Number of currently running worker nodes \\
        GPU Utilization & Current GPU usage percentage \\
        Queue Depth & Number of pending jobs in queue \\
        Storage Used & Total storage consumption \\
        Redis Memory & Redis memory usage \\
        MinIO Bandwidth & Current I/O throughput \\
        \bottomrule
    \end{tabular}
    \caption{System monitoring metrics}
\end{table}

\section{Performance Optimization}

The application implements several optimization strategies:

\begin{itemize}
    \item \textbf{Lazy Loading}: Components are loaded on-demand to reduce initial bundle size
    \item \textbf{State Persistence}: LocalStorage caching reduces API calls
    \item \textbf{Responsive Design}: Optimized for various screen sizes
    \item \textbf{Keyboard Shortcuts}: Power user features for efficiency
\end{itemize}

\section{Expected Performance}

\begin{table}[H]
    \centering
    \begin{tabular}{@{}lll@{}}
        \toprule
        \textbf{Metric} & \textbf{Target} & \textbf{Acceptable Range} \\
        \midrule
        Initial Load Time & < 2 seconds & < 3 seconds \\
        Navigation Response & < 500ms & < 1 second \\
        Memory Usage & < 100MB & < 200MB \\
        Bundle Size & < 500KB & < 1MB \\
        \bottomrule
    \end{tabular}
    \caption{Performance targets and thresholds}
\end{table}

\chapter{Best Practices and Troubleshooting}

\section{Development Best Practices}

\subsection{Code Organization}

\begin{itemize}
    \item Maintain clear separation between components and business logic
    \item Use TypeScript interfaces for all data structures
    \item Implement proper error handling and loading states
    \item Follow React hooks best practices
    \item Use consistent naming conventions
\end{itemize}

\subsection{State Management}

\begin{itemize}
    \item Keep state as close to where it's used as possible
    \item Use localStorage for persistence of user preferences
    \item Implement proper cleanup in useEffect hooks
    \item Avoid unnecessary re-renders through memoization
\end{itemize}

\section{Common Issues and Solutions}

\subsection{Build Failures}

\textbf{Issue}: Build fails with TypeScript errors\\
\textbf{Solution}: Ensure all interfaces are properly typed and imports are correct

\textbf{Issue}: Docker build fails during npm install\\
\textbf{Solution}: Clear npm cache and rebuild: \texttt{npm cache clean --force}

\subsection{Runtime Issues}

\textbf{Issue}: Application doesn't render in browser\\
\textbf{Solution}: Check that JavaScript bundle is properly generated and referenced

\textbf{Issue}: External services not accessible\\
\textbf{Solution}: Verify service URLs in configuration and network connectivity

\subsection{Performance Issues}

\textbf{Issue}: Slow initial load time\\
\textbf{Solution}: Implement code splitting and lazy loading

\textbf{Issue}: Memory leaks in browser\\
\textbf{Solution}: Ensure proper cleanup of event listeners and timers

\section{Debugging Techniques}

\begin{lstlisting}[language=TypeScript, caption=Debugging Configuration]
// Enable debug mode
const DEBUG = process.env.NODE_ENV === 'development';

if (DEBUG) {
  console.log('Debug mode enabled');
  // Additional debug logging
}

// Error boundary implementation
class ErrorBoundary extends React.Component {
  componentDidCatch(error: Error, errorInfo: React.ErrorInfo) {
    console.error('Application error:', error, errorInfo);
  }
}
\end{lstlisting}

\chapter{Conclusions and Future Work}

\section{Project Summary}

NeuroForge AI successfully demonstrates a modern approach to MLOps orchestration, providing a comprehensive platform for managing machine learning workflows. The implementation showcases best practices in React development, TypeScript usage, and containerized deployment strategies. The platform's modular architecture and extensible design make it suitable for various organizational needs and scales.

\section{Key Achievements}

\begin{itemize}
    \item Successfully integrated multiple MLOps tools into a unified interface
    \item Implemented responsive design that works across devices
    \item Created a scalable architecture that supports future enhancements
    \item Established proper development and deployment workflows
    \item Provided comprehensive documentation and examples
\end{itemize}

\section{Future Enhancements}

\subsection{Short-term Goals}

\begin{itemize}
    \item Enhanced monitoring and alerting capabilities
    \item Integration with additional ML frameworks
    \item Improved mobile responsiveness
    \item Advanced user analytics and reporting
\end{itemize}

\subsection{Long-term Vision}

\begin{itemize}
    \item Multi-cloud deployment support
    \item Advanced AI-powered automation features
    \item Integration with enterprise authentication systems
    \item Real-time collaboration features
    \item Advanced experiment comparison tools
\end{itemize}

\section{Technical Debt and Improvements}

\begin{itemize}
    \item Migration to more robust state management solution
    \item Implementation of comprehensive testing suite
    \item Enhanced error handling and recovery mechanisms
    \item Performance optimization for large-scale deployments
\end{itemize}

\chapter{Bibliography}

\begin{thebibliography}{9}

\bibitem{react2023}
React Documentation Team.
\textit{React 18 Documentation}.
React, 2023.
Available at: \url{https://react.dev}

\bibitem{typescript2023}
Microsoft Corporation.
\textit{TypeScript Handbook}.
Microsoft, 2023.
Available at: \url{https://www.typescriptlang.org/docs}

\bibitem{docker2023}
Docker Inc.
\textit{Docker Documentation}.
Docker, 2023.
Available at: \url{https://docs.docker.com}

\bibitem{mlops2023}
Google Cloud.
\textit{MLOps: Continuous delivery and automation pipelines in machine learning}.
Google Cloud, 2023.

\bibitem{vite2023}
Vite Team.
\textit{Vite Documentation}.
Vite, 2023.
Available at: \url{https://vitejs.dev}

\end{thebibliography}

\appendix

\chapter{Advanced Configuration}

\section{Custom Service Integration}

To add custom services to NeuroForge AI, modify the service configuration:

\begin{lstlisting}[language=TypeScript, caption=Custom Service Addition]
const customService: Microservice = {
  id: 'custom-service',
  name: 'Custom ML Service',
  description: 'Custom machine learning service',
  url: 'https://custom-service.example.com',
  icon: <CustomIcon size={20} />,
  minRole: 'admin'
};

// Add to services array
const services = [...DEFAULT_MICROSERVICES, customService];
\end{lstlisting}

\section{Environment Variables Reference}

\begin{table}[H]
    \centering
    \begin{tabular}{@{}ll@{}}
        \toprule
        \textbf{Variable} & \textbf{Description} \\
        \midrule
        GEMINI\_API\_KEY & Google Gemini AI API key \\
        NODE\_ENV & Environment mode (development/production) \\
        PORT & Application port number \\
        MLFLOW\_URL & MLflow server URL \\
        REDIS\_URL & Redis server URL \\
        MINIO\_URL & MinIO server URL \\
        \bottomrule
    \end{tabular}
    \caption{Complete environment variables reference}
\end{table}

\section{Docker Compose Configuration}

\begin{lstlisting}[language=yaml, caption=Complete Docker Compose Setup]
version: '3.8'

services:
  app:
    build: .
    image: wisrovi/neuralforgeai:latest
    ports:
      - "5810:4173"
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
    env_file:
      - .env
    restart: unless-stopped
    
  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
    restart: unless-stopped
    
  mlflow:
    image: python:3.9-slim
    ports:
      - "5000:5000"
    command: mlflow server --host 0.0.0.0
    restart: unless-stopped
\end{lstlisting}

\section{API Integration Examples}

\begin{lstlisting}[language=TypeScript, caption=External API Integration]
const fetchDashboardData = async () => {
  try {
    const response = await fetch(DASHBOARD_API_CONFIG.activeWorkers.url, {
      method: DASHBOARD_API_CONFIG.activeWorkers.method,
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(DASHBOARD_API_CONFIG.activeWorkers.payload)
    });
    
    const data = await response.json();
    return data;
  } catch (error) {
    console.error('Failed to fetch dashboard data:', error);
    return null;
  }
};
\end{lstlisting}

\begin{titlepage}
    \centering
    \vspace*{3cm}
    {\Huge\textbf{Acknowledgments}}\\[1cm]
    {\Large\textit{Special thanks to the open-source community}}\\[0.5cm]
    {\large for providing the tools and libraries that made this project possible}\\[1cm]
    {\large\textit{React, TypeScript, Vite, Docker, and countless contributors}}\\[2cm]
    \colorbox{blue!70!black}{
        \color{white}\textbf{Building the Future of MLOps Together}
    }
\end{titlepage}

\end{document}